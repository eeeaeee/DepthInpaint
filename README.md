# Blind Image Inpainting with Depth Guidance and DUCKBlock

This repository presents a **Transformer-based blind image inpainting model** that integrates:
- âœ… Depth-guided dual attention
- âœ… Wavelet-based frequency-aware feature decomposition
- âœ… Multi-branch DUCKBlock for robust structure modeling

The method is designed for **mask-free inpainting** of corrupted images, leveraging both RGB and estimated depth modalities to achieve semantically and structurally consistent restorations.

---

## ðŸ§± Architecture

<p align="center">
  <img src="architecture.jpg" alt="Model Architecture" width="70%">
</p>

---

## ðŸ“ Dataset Structure

Organize your dataset as follows:

```
datasets/
â”œâ”€â”€ celeb/
â”‚   â”œâ”€â”€ input/      # corrupted images
â”‚   â””â”€â”€ target/     # corresponding ground truth images
â”œâ”€â”€ ffhq/
â”‚   â”œâ”€â”€ input/
â”‚   â””â”€â”€ target/
â””â”€â”€ ...             # other datasets (optional)
```

> ðŸ“Œ *Depth maps* should be stored separately and automatically loaded via filename matching in the training script.

---

## ðŸš€ Training

Use the following command to start training:

```bash
python main.py
```

All training hyperparameters (e.g. transformer depth, batch size, patch size) are configurable via `utils_train.py`.

---
